{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 親ディレクトリのファイルをインポートするための設定\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 過学習を再現するために、学習データを削減\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropuoutの有無、割り合いの設定 ========================\n",
    "use_dropout = True  # Dropoutなしのときの場合はFalseに\n",
    "#消去した割合\n",
    "dropout_ratio = 0.2\n",
    "# ===================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.34199043341104\n",
      "=== epoch:1, train acc:0.13666666666666666, test acc:0.1046 ===\n",
      "train loss:2.3280018871313577\n",
      "train loss:2.3186849804835266\n",
      "train loss:2.3185685014577326\n",
      "=== epoch:2, train acc:0.14, test acc:0.1058 ===\n",
      "train loss:2.330131290381574\n",
      "train loss:2.3006592412142397\n",
      "train loss:2.333240440957601\n",
      "=== epoch:3, train acc:0.14, test acc:0.1089 ===\n",
      "train loss:2.3281563282744275\n",
      "train loss:2.323494610500098\n",
      "train loss:2.3061223336427537\n",
      "=== epoch:4, train acc:0.14333333333333334, test acc:0.1098 ===\n",
      "train loss:2.315379677768546\n",
      "train loss:2.3269325950022353\n",
      "train loss:2.3121898402752254\n",
      "=== epoch:5, train acc:0.14333333333333334, test acc:0.1106 ===\n",
      "train loss:2.3134335616485013\n",
      "train loss:2.302311788670613\n",
      "train loss:2.305611650324421\n",
      "=== epoch:6, train acc:0.15, test acc:0.1109 ===\n",
      "train loss:2.3211046576603795\n",
      "train loss:2.310791715610426\n",
      "train loss:2.3194375579694784\n",
      "=== epoch:7, train acc:0.15, test acc:0.113 ===\n",
      "train loss:2.303439277615259\n",
      "train loss:2.301912137263576\n",
      "train loss:2.3106223431056057\n",
      "=== epoch:8, train acc:0.15, test acc:0.1152 ===\n",
      "train loss:2.2885616151683426\n",
      "train loss:2.3101330642642055\n",
      "train loss:2.298639064103867\n",
      "=== epoch:9, train acc:0.15333333333333332, test acc:0.1167 ===\n",
      "train loss:2.30312266955073\n",
      "train loss:2.2797169113152616\n",
      "train loss:2.3189750957499924\n",
      "=== epoch:10, train acc:0.15666666666666668, test acc:0.1183 ===\n",
      "train loss:2.288460211781885\n",
      "train loss:2.2913553237478976\n",
      "train loss:2.3041288958650425\n",
      "=== epoch:11, train acc:0.15666666666666668, test acc:0.119 ===\n",
      "train loss:2.305209467744469\n",
      "train loss:2.300350750780901\n",
      "train loss:2.303703850281644\n",
      "=== epoch:12, train acc:0.15666666666666668, test acc:0.1207 ===\n",
      "train loss:2.31457048527714\n",
      "train loss:2.295739205785975\n",
      "train loss:2.2933354471018133\n",
      "=== epoch:13, train acc:0.15, test acc:0.1199 ===\n",
      "train loss:2.297926901866842\n",
      "train loss:2.2863511157861485\n",
      "train loss:2.2990531927754048\n",
      "=== epoch:14, train acc:0.15, test acc:0.1203 ===\n",
      "train loss:2.2870742082704\n",
      "train loss:2.293758277619374\n",
      "train loss:2.2930846125367887\n",
      "=== epoch:15, train acc:0.15, test acc:0.1208 ===\n",
      "train loss:2.2937526322297814\n",
      "train loss:2.2854070806758533\n",
      "train loss:2.296597929527205\n",
      "=== epoch:16, train acc:0.15333333333333332, test acc:0.1222 ===\n",
      "train loss:2.2780984564353806\n",
      "train loss:2.29132021828363\n",
      "train loss:2.285804751585321\n",
      "=== epoch:17, train acc:0.17333333333333334, test acc:0.1255 ===\n",
      "train loss:2.2845449209085666\n",
      "train loss:2.2897442498988494\n",
      "train loss:2.279840142548119\n",
      "=== epoch:18, train acc:0.16333333333333333, test acc:0.1277 ===\n",
      "train loss:2.299558112598625\n",
      "train loss:2.280915754244969\n",
      "train loss:2.291842649507103\n",
      "=== epoch:19, train acc:0.16333333333333333, test acc:0.1307 ===\n",
      "train loss:2.282088430812488\n",
      "train loss:2.279721042370063\n",
      "train loss:2.292484761444383\n",
      "=== epoch:20, train acc:0.16666666666666666, test acc:0.1342 ===\n",
      "train loss:2.2771969776684338\n",
      "train loss:2.2851247936265024\n",
      "train loss:2.285673431550743\n",
      "=== epoch:21, train acc:0.16333333333333333, test acc:0.1379 ===\n",
      "train loss:2.2829867333892717\n",
      "train loss:2.285121472662682\n",
      "train loss:2.2834460628344235\n",
      "=== epoch:22, train acc:0.16666666666666666, test acc:0.1423 ===\n",
      "train loss:2.286900774471381\n",
      "train loss:2.278990184477867\n",
      "train loss:2.283097221284387\n",
      "=== epoch:23, train acc:0.16666666666666666, test acc:0.1466 ===\n",
      "train loss:2.2761430956871056\n",
      "train loss:2.284452187291871\n",
      "train loss:2.2795411388807305\n",
      "=== epoch:24, train acc:0.17333333333333334, test acc:0.1472 ===\n",
      "train loss:2.2870245424023325\n",
      "train loss:2.281725415438613\n",
      "train loss:2.2771673801663908\n",
      "=== epoch:25, train acc:0.16666666666666666, test acc:0.1523 ===\n",
      "train loss:2.279414913820689\n",
      "train loss:2.2775744502914086\n",
      "train loss:2.2678805641826294\n",
      "=== epoch:26, train acc:0.18, test acc:0.156 ===\n",
      "train loss:2.2685949849451883\n",
      "train loss:2.2726524182124597\n",
      "train loss:2.2761835490546427\n",
      "=== epoch:27, train acc:0.18333333333333332, test acc:0.1598 ===\n",
      "train loss:2.2758149587716847\n",
      "train loss:2.2697594314170044\n",
      "train loss:2.2813011662039333\n",
      "=== epoch:28, train acc:0.19, test acc:0.1616 ===\n",
      "train loss:2.2776823705715694\n",
      "train loss:2.2842661776352178\n",
      "train loss:2.2761141814212493\n",
      "=== epoch:29, train acc:0.20333333333333334, test acc:0.1653 ===\n",
      "train loss:2.2776793566030014\n",
      "train loss:2.2781123290096588\n",
      "train loss:2.258793588157581\n",
      "=== epoch:30, train acc:0.19, test acc:0.1669 ===\n",
      "train loss:2.2882706305930087\n",
      "train loss:2.261758526624826\n",
      "train loss:2.269559984676028\n",
      "=== epoch:31, train acc:0.21, test acc:0.1739 ===\n",
      "train loss:2.274839475560386\n",
      "train loss:2.269454548581501\n",
      "train loss:2.2736966655618165\n",
      "=== epoch:32, train acc:0.21333333333333335, test acc:0.1792 ===\n",
      "train loss:2.2644835947250725\n",
      "train loss:2.2661024455916174\n",
      "train loss:2.260599121967125\n",
      "=== epoch:33, train acc:0.21666666666666667, test acc:0.1814 ===\n",
      "train loss:2.270453338925938\n",
      "train loss:2.259890387886122\n",
      "train loss:2.280055447682382\n",
      "=== epoch:34, train acc:0.22333333333333333, test acc:0.1838 ===\n",
      "train loss:2.263781038333118\n",
      "train loss:2.2634265552335036\n",
      "train loss:2.262524847953579\n",
      "=== epoch:35, train acc:0.23333333333333334, test acc:0.191 ===\n",
      "train loss:2.25116221322684\n",
      "train loss:2.2483790550997713\n",
      "train loss:2.2479969965325366\n",
      "=== epoch:36, train acc:0.24666666666666667, test acc:0.1936 ===\n",
      "train loss:2.265214483906924\n",
      "train loss:2.25758988883755\n",
      "train loss:2.2527057601731895\n",
      "=== epoch:37, train acc:0.25, test acc:0.1953 ===\n",
      "train loss:2.2625063220431385\n",
      "train loss:2.25718749376058\n",
      "train loss:2.260425702154114\n",
      "=== epoch:38, train acc:0.25, test acc:0.1989 ===\n",
      "train loss:2.277761668272395\n",
      "train loss:2.2589476795927883\n",
      "train loss:2.256271222668904\n",
      "=== epoch:39, train acc:0.25666666666666665, test acc:0.2035 ===\n",
      "train loss:2.258999960221709\n",
      "train loss:2.256337906407329\n",
      "train loss:2.243340032671277\n",
      "=== epoch:40, train acc:0.26, test acc:0.2078 ===\n",
      "train loss:2.262316881009584\n",
      "train loss:2.255472426535762\n",
      "train loss:2.2609939252068805\n",
      "=== epoch:41, train acc:0.26, test acc:0.2107 ===\n",
      "train loss:2.263996985043128\n",
      "train loss:2.2518946282569323\n",
      "train loss:2.2497778027951485\n",
      "=== epoch:42, train acc:0.26, test acc:0.21 ===\n",
      "train loss:2.2598539887275204\n",
      "train loss:2.24551230370236\n",
      "train loss:2.256092744857222\n",
      "=== epoch:43, train acc:0.26, test acc:0.2116 ===\n",
      "train loss:2.255693901377015\n",
      "train loss:2.260318310286587\n",
      "train loss:2.257227283127395\n",
      "=== epoch:44, train acc:0.27, test acc:0.2139 ===\n",
      "train loss:2.262281295431604\n",
      "train loss:2.247124304639126\n",
      "train loss:2.250755145306306\n",
      "=== epoch:45, train acc:0.2633333333333333, test acc:0.2143 ===\n",
      "train loss:2.2563397056143875\n",
      "train loss:2.2675173714006123\n",
      "train loss:2.252132557170069\n",
      "=== epoch:46, train acc:0.26666666666666666, test acc:0.2156 ===\n",
      "train loss:2.251436567085209\n",
      "train loss:2.2638050399575387\n",
      "train loss:2.251745197343602\n",
      "=== epoch:47, train acc:0.27666666666666667, test acc:0.2188 ===\n",
      "train loss:2.2494377344828207\n",
      "train loss:2.2607169336752477\n",
      "train loss:2.239641488066543\n",
      "=== epoch:48, train acc:0.2833333333333333, test acc:0.2231 ===\n",
      "train loss:2.2517147557265975\n",
      "train loss:2.2401599468550324\n",
      "train loss:2.2542044237357444\n",
      "=== epoch:49, train acc:0.2833333333333333, test acc:0.2254 ===\n",
      "train loss:2.250910886749617\n",
      "train loss:2.2547576929298447\n",
      "train loss:2.23548916832217\n",
      "=== epoch:50, train acc:0.29, test acc:0.2275 ===\n",
      "train loss:2.266203828069161\n",
      "train loss:2.241317051753997\n",
      "train loss:2.2223728413624895\n",
      "=== epoch:51, train acc:0.2866666666666667, test acc:0.2297 ===\n",
      "train loss:2.237966700065104\n",
      "train loss:2.2509259927433387\n",
      "train loss:2.2166719320103647\n",
      "=== epoch:52, train acc:0.3, test acc:0.2325 ===\n",
      "train loss:2.2329848578350124\n",
      "train loss:2.2341777452756855\n",
      "train loss:2.251949778274635\n",
      "=== epoch:53, train acc:0.2966666666666667, test acc:0.2323 ===\n",
      "train loss:2.239799693935772\n",
      "train loss:2.258535937020275\n",
      "train loss:2.2434761254699485\n",
      "=== epoch:54, train acc:0.2966666666666667, test acc:0.2347 ===\n",
      "train loss:2.2485209183293655\n",
      "train loss:2.2455244731248865\n",
      "train loss:2.230330373799634\n",
      "=== epoch:55, train acc:0.3, test acc:0.2349 ===\n",
      "train loss:2.2276152835309704\n",
      "train loss:2.2317612941722946\n",
      "train loss:2.2416149121746147\n",
      "=== epoch:56, train acc:0.3, test acc:0.2361 ===\n",
      "train loss:2.233969519107411\n",
      "train loss:2.229312898864764\n",
      "train loss:2.236146588520527\n",
      "=== epoch:57, train acc:0.2966666666666667, test acc:0.2371 ===\n",
      "train loss:2.238511450701705\n",
      "train loss:2.2146194411189937\n",
      "train loss:2.2384086420951372\n",
      "=== epoch:58, train acc:0.30333333333333334, test acc:0.2396 ===\n",
      "train loss:2.2257109139791025\n",
      "train loss:2.2291362969647674\n",
      "train loss:2.2296129625587486\n",
      "=== epoch:59, train acc:0.31, test acc:0.2414 ===\n",
      "train loss:2.23661071733466\n",
      "train loss:2.2360076415652284\n",
      "train loss:2.2321738922357146\n",
      "=== epoch:60, train acc:0.30333333333333334, test acc:0.2428 ===\n",
      "train loss:2.2224802022300145\n",
      "train loss:2.2364870831606636\n",
      "train loss:2.2316647525155826\n",
      "=== epoch:61, train acc:0.31, test acc:0.245 ===\n",
      "train loss:2.1928238279018326\n",
      "train loss:2.2522304249343734\n",
      "train loss:2.2257841007094403\n",
      "=== epoch:62, train acc:0.31333333333333335, test acc:0.2443 ===\n",
      "train loss:2.2514305968814217\n",
      "train loss:2.2266862922818764\n",
      "train loss:2.215849066436536\n",
      "=== epoch:63, train acc:0.31, test acc:0.2466 ===\n",
      "train loss:2.220379303049724\n",
      "train loss:2.2081325971723116\n",
      "train loss:2.197237545043256\n",
      "=== epoch:64, train acc:0.31333333333333335, test acc:0.2455 ===\n",
      "train loss:2.213579424346882\n",
      "train loss:2.217120102044816\n",
      "train loss:2.2235551946948138\n",
      "=== epoch:65, train acc:0.31, test acc:0.2465 ===\n",
      "train loss:2.2099394082677684\n",
      "train loss:2.2101874807518045\n",
      "train loss:2.212658278433982\n",
      "=== epoch:66, train acc:0.31, test acc:0.2465 ===\n",
      "train loss:2.216310610666324\n",
      "train loss:2.2145488181587343\n",
      "train loss:2.2088589361435664\n",
      "=== epoch:67, train acc:0.31, test acc:0.2486 ===\n",
      "train loss:2.214510073316352\n",
      "train loss:2.2111601940952577\n",
      "train loss:2.2288260440419023\n",
      "=== epoch:68, train acc:0.31, test acc:0.2506 ===\n",
      "train loss:2.2273894827558953\n",
      "train loss:2.2113285946965195\n",
      "train loss:2.202728534502691\n",
      "=== epoch:69, train acc:0.31333333333333335, test acc:0.2507 ===\n",
      "train loss:2.2151696105042458\n",
      "train loss:2.204405739848058\n",
      "train loss:2.223981541158782\n",
      "=== epoch:70, train acc:0.3233333333333333, test acc:0.2512 ===\n",
      "train loss:2.2014976672754036\n",
      "train loss:2.224846953050776\n",
      "train loss:2.1979760138202202\n",
      "=== epoch:71, train acc:0.33, test acc:0.2523 ===\n",
      "train loss:2.2257754716031926\n",
      "train loss:2.2014192954326073\n",
      "train loss:2.202362215897973\n",
      "=== epoch:72, train acc:0.3333333333333333, test acc:0.2529 ===\n",
      "train loss:2.221102118857766\n",
      "train loss:2.202188897401607\n",
      "train loss:2.205120885692843\n",
      "=== epoch:73, train acc:0.33, test acc:0.2549 ===\n",
      "train loss:2.222662760893005\n",
      "train loss:2.207697929758755\n",
      "train loss:2.2090487647597197\n",
      "=== epoch:74, train acc:0.32666666666666666, test acc:0.2526 ===\n",
      "train loss:2.187625136724623\n",
      "train loss:2.1994711234742508\n",
      "train loss:2.1974508012634915\n",
      "=== epoch:75, train acc:0.31666666666666665, test acc:0.2511 ===\n",
      "train loss:2.219494530308138\n",
      "train loss:2.202460523437008\n",
      "train loss:2.2088748124726916\n",
      "=== epoch:76, train acc:0.31666666666666665, test acc:0.2499 ===\n",
      "train loss:2.2211644715257455\n",
      "train loss:2.1877569628648987\n",
      "train loss:2.1970056579509327\n",
      "=== epoch:77, train acc:0.31666666666666665, test acc:0.2497 ===\n",
      "train loss:2.1857826220829355\n",
      "train loss:2.2200038221389504\n",
      "train loss:2.1999644598653036\n",
      "=== epoch:78, train acc:0.33, test acc:0.2516 ===\n",
      "train loss:2.1918332581508766\n",
      "train loss:2.1877316582728437\n",
      "train loss:2.1804171009626403\n",
      "=== epoch:79, train acc:0.3333333333333333, test acc:0.2499 ===\n",
      "train loss:2.191560803757325\n",
      "train loss:2.219573531405085\n",
      "train loss:2.185939939504125\n",
      "=== epoch:80, train acc:0.32666666666666666, test acc:0.2512 ===\n",
      "train loss:2.168169582121608\n",
      "train loss:2.177719078476283\n",
      "train loss:2.1940064928827847\n",
      "=== epoch:81, train acc:0.33666666666666667, test acc:0.2534 ===\n",
      "train loss:2.1904885604010023\n",
      "train loss:2.1932133590038707\n",
      "train loss:2.180218133867459\n",
      "=== epoch:82, train acc:0.33, test acc:0.2532 ===\n",
      "train loss:2.20102572697206\n",
      "train loss:2.185095559096007\n",
      "train loss:2.195072304163287\n",
      "=== epoch:83, train acc:0.32666666666666666, test acc:0.2541 ===\n",
      "train loss:2.1649529816047406\n",
      "train loss:2.204282369622326\n",
      "train loss:2.169384685451523\n",
      "=== epoch:84, train acc:0.3233333333333333, test acc:0.253 ===\n",
      "train loss:2.171317020506844\n",
      "train loss:2.1747032083435984\n",
      "train loss:2.1747348909718944\n",
      "=== epoch:85, train acc:0.3333333333333333, test acc:0.2506 ===\n",
      "train loss:2.1940019481547073\n",
      "train loss:2.1828754087615105\n",
      "train loss:2.1561392252829252\n",
      "=== epoch:86, train acc:0.3333333333333333, test acc:0.2499 ===\n",
      "train loss:2.1591043252300888\n",
      "train loss:2.167466342052937\n",
      "train loss:2.1950671143808744\n",
      "=== epoch:87, train acc:0.33, test acc:0.252 ===\n",
      "train loss:2.159645613651541\n",
      "train loss:2.2136227276848626\n",
      "train loss:2.1661936783551123\n",
      "=== epoch:88, train acc:0.3333333333333333, test acc:0.2556 ===\n",
      "train loss:2.1564494118093016\n",
      "train loss:2.1768173106580777\n",
      "train loss:2.177961970511202\n",
      "=== epoch:89, train acc:0.3333333333333333, test acc:0.2547 ===\n",
      "train loss:2.20191158945884\n",
      "train loss:2.1723520216835563\n",
      "train loss:2.1584201954063915\n",
      "=== epoch:90, train acc:0.34, test acc:0.254 ===\n",
      "train loss:2.180471974215968\n",
      "train loss:2.161570298746045\n",
      "train loss:2.189729400789544\n",
      "=== epoch:91, train acc:0.34, test acc:0.2569 ===\n",
      "train loss:2.1641328364170604\n",
      "train loss:2.2116153049689897\n",
      "train loss:2.1447975411226823\n",
      "=== epoch:92, train acc:0.34, test acc:0.254 ===\n",
      "train loss:2.1547735353432667\n",
      "train loss:2.1732025405306605\n",
      "train loss:2.1284967714909406\n",
      "=== epoch:93, train acc:0.3333333333333333, test acc:0.2521 ===\n",
      "train loss:2.1601721686693622\n",
      "train loss:2.144865034445049\n",
      "train loss:2.1827194198957205\n",
      "=== epoch:94, train acc:0.33666666666666667, test acc:0.2521 ===\n",
      "train loss:2.1685150932688475\n",
      "train loss:2.153688495792331\n",
      "train loss:2.1251687883604724\n",
      "=== epoch:95, train acc:0.34, test acc:0.2517 ===\n",
      "train loss:2.1570374945278834\n",
      "train loss:2.1611951699044156\n",
      "train loss:2.146183397270346\n",
      "=== epoch:96, train acc:0.33666666666666667, test acc:0.2538 ===\n",
      "train loss:2.1636610139000343\n",
      "train loss:2.164405617344775\n",
      "train loss:2.1558673129366652\n",
      "=== epoch:97, train acc:0.33666666666666667, test acc:0.2542 ===\n",
      "train loss:2.139925911928978\n",
      "train loss:2.1178359229800052\n",
      "train loss:2.1362219515310206\n",
      "=== epoch:98, train acc:0.3333333333333333, test acc:0.2524 ===\n",
      "train loss:2.1473830411357175\n",
      "train loss:2.175082120401796\n",
      "train loss:2.116284551504558\n",
      "=== epoch:99, train acc:0.33, test acc:0.2522 ===\n",
      "train loss:2.143166883260298\n",
      "train loss:2.1250279635945084\n",
      "train loss:2.1512125091948473\n",
      "=== epoch:100, train acc:0.33, test acc:0.2514 ===\n",
      "train loss:2.126143315159527\n",
      "train loss:2.141089176256342\n",
      "train loss:2.1646155832751157\n",
      "=== epoch:101, train acc:0.3333333333333333, test acc:0.2525 ===\n",
      "train loss:2.1509514449178235\n",
      "train loss:2.1180673953596045\n",
      "train loss:2.126613407019306\n",
      "=== epoch:102, train acc:0.3333333333333333, test acc:0.252 ===\n",
      "train loss:2.133581908279788\n",
      "train loss:2.100783393679391\n",
      "train loss:2.175851641692806\n",
      "=== epoch:103, train acc:0.3333333333333333, test acc:0.2528 ===\n",
      "train loss:2.1232128081858006\n",
      "train loss:2.1743198713534513\n",
      "train loss:2.1489517185315554\n",
      "=== epoch:104, train acc:0.3333333333333333, test acc:0.2527 ===\n",
      "train loss:2.1139468678180524\n",
      "train loss:2.1608239649732695\n",
      "train loss:2.1628255185063665\n",
      "=== epoch:105, train acc:0.34, test acc:0.253 ===\n",
      "train loss:2.144185452245431\n",
      "train loss:2.1000708099480896\n",
      "train loss:2.070104207003806\n",
      "=== epoch:106, train acc:0.33666666666666667, test acc:0.2503 ===\n",
      "train loss:2.1158016309935714\n",
      "train loss:2.177703076495043\n",
      "train loss:2.1420844696269175\n",
      "=== epoch:107, train acc:0.33666666666666667, test acc:0.2513 ===\n",
      "train loss:2.13995047739146\n",
      "train loss:2.1238678487715266\n",
      "train loss:2.1197276767682935\n",
      "=== epoch:108, train acc:0.3433333333333333, test acc:0.2531 ===\n",
      "train loss:2.1192021636429716\n",
      "train loss:2.0968507573720006\n",
      "train loss:2.0955131085762564\n",
      "=== epoch:109, train acc:0.34, test acc:0.2548 ===\n",
      "train loss:2.134603430197545\n",
      "train loss:2.0958168488802653\n",
      "train loss:2.1244103722329792\n",
      "=== epoch:110, train acc:0.3466666666666667, test acc:0.2572 ===\n",
      "train loss:2.089323310112467\n",
      "train loss:2.067921538318807\n",
      "train loss:2.1155684215708943\n",
      "=== epoch:111, train acc:0.35, test acc:0.2593 ===\n",
      "train loss:2.0701328038362834\n",
      "train loss:2.0859561518815593\n",
      "train loss:2.103460346376348\n",
      "=== epoch:112, train acc:0.35333333333333333, test acc:0.259 ===\n",
      "train loss:2.096933742279747\n",
      "train loss:2.112951383014601\n",
      "train loss:2.0924880730785933\n",
      "=== epoch:113, train acc:0.35, test acc:0.258 ===\n",
      "train loss:2.077565397396173\n",
      "train loss:2.113322173773196\n",
      "train loss:2.087283880897131\n",
      "=== epoch:114, train acc:0.35, test acc:0.2589 ===\n",
      "train loss:2.1004637271183593\n",
      "train loss:2.1158147222167827\n",
      "train loss:2.048422174022296\n",
      "=== epoch:115, train acc:0.36, test acc:0.2591 ===\n",
      "train loss:2.115838190197244\n",
      "train loss:2.079825471034851\n",
      "train loss:2.0895000997877107\n",
      "=== epoch:116, train acc:0.36333333333333334, test acc:0.2618 ===\n",
      "train loss:2.0878799113642814\n",
      "train loss:2.0625274918488015\n",
      "train loss:2.0666338300570937\n",
      "=== epoch:117, train acc:0.36, test acc:0.2643 ===\n",
      "train loss:2.0511002804766734\n",
      "train loss:2.037027323568479\n",
      "train loss:2.075081220251649\n",
      "=== epoch:118, train acc:0.36, test acc:0.2634 ===\n",
      "train loss:2.074812103584722\n",
      "train loss:2.0507227167860584\n",
      "train loss:2.0567570223277043\n",
      "=== epoch:119, train acc:0.36666666666666664, test acc:0.2665 ===\n",
      "train loss:2.0313565020841797\n",
      "train loss:2.024033216401294\n",
      "train loss:2.106359818997626\n",
      "=== epoch:120, train acc:0.36666666666666664, test acc:0.2678 ===\n",
      "train loss:2.052612036088655\n",
      "train loss:2.054644476183162\n",
      "train loss:2.0834218479756355\n",
      "=== epoch:121, train acc:0.36666666666666664, test acc:0.2691 ===\n",
      "train loss:2.040149848035358\n",
      "train loss:2.0487554661683585\n",
      "train loss:2.0706413783040585\n",
      "=== epoch:122, train acc:0.37, test acc:0.2724 ===\n",
      "train loss:2.0549970282173673\n",
      "train loss:2.010769658532476\n",
      "train loss:2.056079501968003\n",
      "=== epoch:123, train acc:0.37666666666666665, test acc:0.2732 ===\n",
      "train loss:2.04421568482833\n",
      "train loss:1.968455522917762\n",
      "train loss:2.0489907946925707\n",
      "=== epoch:124, train acc:0.36333333333333334, test acc:0.2696 ===\n",
      "train loss:2.0484684284038517\n",
      "train loss:2.1049859223302874\n",
      "train loss:2.0358293524488245\n",
      "=== epoch:125, train acc:0.36333333333333334, test acc:0.2675 ===\n",
      "train loss:2.029980143300822\n",
      "train loss:2.003365124012463\n",
      "train loss:2.0887806735550463\n",
      "=== epoch:126, train acc:0.36333333333333334, test acc:0.2676 ===\n",
      "train loss:2.0334307347880682\n",
      "train loss:2.0084785170138684\n",
      "train loss:1.965194029310864\n",
      "=== epoch:127, train acc:0.36333333333333334, test acc:0.264 ===\n",
      "train loss:2.0555591578638763\n",
      "train loss:2.0412213079489097\n",
      "train loss:2.0881133581702738\n",
      "=== epoch:128, train acc:0.37, test acc:0.2651 ===\n",
      "train loss:2.0099903637989813\n",
      "train loss:1.9996307838965393\n",
      "train loss:2.061823336045649\n",
      "=== epoch:129, train acc:0.37333333333333335, test acc:0.2694 ===\n",
      "train loss:1.9919802282508852\n",
      "train loss:2.035969552017253\n",
      "train loss:1.976972075249316\n",
      "=== epoch:130, train acc:0.37333333333333335, test acc:0.2708 ===\n",
      "train loss:1.9717807789183146\n",
      "train loss:2.017741819772013\n",
      "train loss:2.0609643930852575\n",
      "=== epoch:131, train acc:0.38, test acc:0.2741 ===\n",
      "train loss:2.0471736972565067\n",
      "train loss:2.0378070258836893\n",
      "train loss:1.9609218874950807\n",
      "=== epoch:132, train acc:0.38, test acc:0.2767 ===\n",
      "train loss:2.005172121237585\n",
      "train loss:2.0447798054658284\n",
      "train loss:2.056875934217681\n",
      "=== epoch:133, train acc:0.38333333333333336, test acc:0.2783 ===\n",
      "train loss:2.00655757134632\n",
      "train loss:1.9955558110464502\n",
      "train loss:1.9507844961246905\n",
      "=== epoch:134, train acc:0.38333333333333336, test acc:0.2777 ===\n",
      "train loss:2.011893004540396\n",
      "train loss:1.980462789072558\n",
      "train loss:2.0236208705733767\n",
      "=== epoch:135, train acc:0.38666666666666666, test acc:0.2791 ===\n",
      "train loss:1.9677405775988996\n",
      "train loss:2.0274358337937115\n",
      "train loss:1.8723364484027396\n",
      "=== epoch:136, train acc:0.38666666666666666, test acc:0.2784 ===\n",
      "train loss:1.9031613650931503\n",
      "train loss:1.9343503692263349\n",
      "train loss:2.0160221736529222\n",
      "=== epoch:137, train acc:0.38666666666666666, test acc:0.2779 ===\n",
      "train loss:1.9564891517154224\n",
      "train loss:1.9907670962017097\n",
      "train loss:2.0086915916981267\n",
      "=== epoch:138, train acc:0.38333333333333336, test acc:0.28 ===\n",
      "train loss:1.9861436599012479\n",
      "train loss:1.9265475667930363\n",
      "train loss:2.043985417029297\n",
      "=== epoch:139, train acc:0.39, test acc:0.2819 ===\n",
      "train loss:1.8835667844475639\n",
      "train loss:1.9624371976386343\n",
      "train loss:1.9225866187427751\n",
      "=== epoch:140, train acc:0.38333333333333336, test acc:0.2802 ===\n",
      "train loss:1.9392901436563061\n",
      "train loss:1.970460097654407\n",
      "train loss:2.0141272384615965\n",
      "=== epoch:141, train acc:0.3933333333333333, test acc:0.282 ===\n",
      "train loss:1.9547152465116773\n",
      "train loss:1.9120840482292838\n",
      "train loss:1.9774228123717874\n",
      "=== epoch:142, train acc:0.39666666666666667, test acc:0.2841 ===\n",
      "train loss:1.9342236830944541\n",
      "train loss:1.9294589545241596\n",
      "train loss:1.9382891026493494\n",
      "=== epoch:143, train acc:0.3933333333333333, test acc:0.2841 ===\n",
      "train loss:1.902822856464692\n",
      "train loss:1.924282206634148\n",
      "train loss:1.9189046078918168\n",
      "=== epoch:144, train acc:0.39, test acc:0.284 ===\n",
      "train loss:1.9185357858471304\n",
      "train loss:1.9107164073514142\n",
      "train loss:1.9034130721953093\n",
      "=== epoch:145, train acc:0.38333333333333336, test acc:0.2825 ===\n",
      "train loss:1.8839703847989455\n",
      "train loss:1.97828051194218\n",
      "train loss:1.8727423258092686\n",
      "=== epoch:146, train acc:0.38666666666666666, test acc:0.2877 ===\n",
      "train loss:1.899610023931346\n",
      "train loss:1.91926680179603\n",
      "train loss:1.9369954664114664\n",
      "=== epoch:147, train acc:0.39, test acc:0.2861 ===\n",
      "train loss:1.9430273051396727\n",
      "train loss:1.8944990042029088\n",
      "train loss:1.8732161348468606\n",
      "=== epoch:148, train acc:0.39, test acc:0.2887 ===\n",
      "train loss:1.900882818047292\n",
      "train loss:1.9565198770748808\n",
      "train loss:1.8453232175658312\n",
      "=== epoch:149, train acc:0.38666666666666666, test acc:0.2877 ===\n",
      "train loss:1.9522467993728014\n",
      "train loss:1.928775549900493\n",
      "train loss:1.9269380833060752\n",
      "=== epoch:150, train acc:0.3933333333333333, test acc:0.2919 ===\n",
      "train loss:1.8869034774507525\n",
      "train loss:1.9237579099726418\n",
      "train loss:1.8913702785632964\n",
      "=== epoch:151, train acc:0.3933333333333333, test acc:0.2904 ===\n",
      "train loss:1.8479847646166103\n",
      "train loss:1.841615549736742\n",
      "train loss:1.8936142594070358\n",
      "=== epoch:152, train acc:0.39, test acc:0.2892 ===\n",
      "train loss:1.9037489889438017\n",
      "train loss:1.8009201395873493\n",
      "train loss:1.985046544806873\n",
      "=== epoch:153, train acc:0.38666666666666666, test acc:0.2905 ===\n",
      "train loss:1.9070860323635597\n",
      "train loss:1.9101078497674235\n",
      "train loss:1.9171274380473229\n",
      "=== epoch:154, train acc:0.38666666666666666, test acc:0.2911 ===\n",
      "train loss:1.8920543510300576\n",
      "train loss:1.927187411782492\n",
      "train loss:1.8760938869601225\n",
      "=== epoch:155, train acc:0.38333333333333336, test acc:0.2906 ===\n",
      "train loss:1.9227438224797786\n",
      "train loss:1.8843068685987168\n",
      "train loss:1.8820715117704787\n",
      "=== epoch:156, train acc:0.3933333333333333, test acc:0.2946 ===\n",
      "train loss:1.8520951079454682\n",
      "train loss:1.8849106364571018\n",
      "train loss:1.8527368895371439\n",
      "=== epoch:157, train acc:0.4, test acc:0.2961 ===\n",
      "train loss:1.864940649944471\n",
      "train loss:1.8626749873265036\n",
      "train loss:1.7760969293101838\n",
      "=== epoch:158, train acc:0.38666666666666666, test acc:0.2947 ===\n",
      "train loss:1.7487291377776812\n",
      "train loss:1.822904621728256\n",
      "train loss:1.8611926383664743\n",
      "=== epoch:159, train acc:0.39, test acc:0.2951 ===\n",
      "train loss:1.8626485516176916\n",
      "train loss:1.8339284921962637\n",
      "train loss:1.7611687564492768\n",
      "=== epoch:160, train acc:0.4, test acc:0.296 ===\n",
      "train loss:1.8924777734493683\n",
      "train loss:1.8985432095369827\n",
      "train loss:1.8276095292044041\n",
      "=== epoch:161, train acc:0.4033333333333333, test acc:0.2981 ===\n",
      "train loss:1.8405697739448865\n",
      "train loss:1.8875142840739068\n",
      "train loss:1.9019798518215447\n",
      "=== epoch:162, train acc:0.4066666666666667, test acc:0.3012 ===\n",
      "train loss:1.8390065323582163\n",
      "train loss:1.8585743466620501\n",
      "train loss:1.8513262817871066\n",
      "=== epoch:163, train acc:0.41333333333333333, test acc:0.308 ===\n",
      "train loss:1.8274050122943968\n",
      "train loss:1.8093699142524127\n",
      "train loss:1.8490153157491322\n",
      "=== epoch:164, train acc:0.4166666666666667, test acc:0.3105 ===\n",
      "train loss:1.805902189671997\n",
      "train loss:1.8007082518297743\n",
      "train loss:1.765896671848099\n",
      "=== epoch:165, train acc:0.4166666666666667, test acc:0.3096 ===\n",
      "train loss:1.8248980391584135\n",
      "train loss:1.7427148223908162\n",
      "train loss:1.8544249395395718\n",
      "=== epoch:166, train acc:0.41333333333333333, test acc:0.3113 ===\n",
      "train loss:1.8202255652900556\n",
      "train loss:1.8916576170085708\n",
      "train loss:1.7822529020293352\n",
      "=== epoch:167, train acc:0.42, test acc:0.3118 ===\n",
      "train loss:1.7599072002594243\n",
      "train loss:1.9381928226008371\n",
      "train loss:1.8052334372508392\n",
      "=== epoch:168, train acc:0.4266666666666667, test acc:0.3223 ===\n",
      "train loss:1.845339533716564\n",
      "train loss:1.793959007182346\n",
      "train loss:1.886420659489608\n",
      "=== epoch:169, train acc:0.43333333333333335, test acc:0.3267 ===\n",
      "train loss:1.8015922458549218\n",
      "train loss:1.8162065422042155\n",
      "train loss:1.755817692288084\n",
      "=== epoch:170, train acc:0.44666666666666666, test acc:0.3302 ===\n",
      "train loss:1.702988873009835\n",
      "train loss:1.755148137494711\n",
      "train loss:1.8949109529565569\n",
      "=== epoch:171, train acc:0.43666666666666665, test acc:0.3294 ===\n",
      "train loss:1.8798664462185923\n",
      "train loss:1.6584142224797471\n",
      "train loss:1.718994261024809\n",
      "=== epoch:172, train acc:0.43, test acc:0.3307 ===\n",
      "train loss:1.786638219830881\n",
      "train loss:1.8686343976763786\n",
      "train loss:1.765909810447254\n",
      "=== epoch:173, train acc:0.4533333333333333, test acc:0.3372 ===\n",
      "train loss:1.7297275420858904\n",
      "train loss:1.7200177643633732\n",
      "train loss:1.9515208961889354\n",
      "=== epoch:174, train acc:0.45666666666666667, test acc:0.3394 ===\n",
      "train loss:1.832187348509558\n",
      "train loss:1.75201341523617\n",
      "train loss:1.7102054574622199\n",
      "=== epoch:175, train acc:0.4633333333333333, test acc:0.3442 ===\n",
      "train loss:1.8597907539016914\n",
      "train loss:1.7457171517117458\n",
      "train loss:1.7423915894423703\n",
      "=== epoch:176, train acc:0.4633333333333333, test acc:0.3456 ===\n",
      "train loss:1.7600418302463643\n",
      "train loss:1.8693743684597248\n",
      "train loss:1.7632123215899327\n",
      "=== epoch:177, train acc:0.47, test acc:0.3483 ===\n",
      "train loss:1.7654079696519176\n",
      "train loss:1.683275180946739\n",
      "train loss:1.7417529221774415\n",
      "=== epoch:178, train acc:0.4666666666666667, test acc:0.3499 ===\n",
      "train loss:1.8180161451759997\n",
      "train loss:1.6872997819838704\n",
      "train loss:1.7825070395975873\n",
      "=== epoch:179, train acc:0.4766666666666667, test acc:0.3567 ===\n",
      "train loss:1.6686844541611954\n",
      "train loss:1.7740324510593377\n",
      "train loss:1.802260474243393\n",
      "=== epoch:180, train acc:0.48, test acc:0.3642 ===\n",
      "train loss:1.6887445809347534\n",
      "train loss:1.6846808733382803\n",
      "train loss:1.7080501645267208\n",
      "=== epoch:181, train acc:0.49, test acc:0.364 ===\n",
      "train loss:1.6235120326545112\n",
      "train loss:1.7420942578029526\n",
      "train loss:1.7626826654946064\n",
      "=== epoch:182, train acc:0.5, test acc:0.3686 ===\n",
      "train loss:1.6875882075652868\n",
      "train loss:1.72325915630981\n",
      "train loss:1.6440233550836592\n",
      "=== epoch:183, train acc:0.5, test acc:0.3662 ===\n",
      "train loss:1.6938593828893236\n",
      "train loss:1.825638032661197\n",
      "train loss:1.741826947930677\n",
      "=== epoch:184, train acc:0.48333333333333334, test acc:0.3671 ===\n",
      "train loss:1.641954198355933\n",
      "train loss:1.6146188257510858\n",
      "train loss:1.7584052154369514\n",
      "=== epoch:185, train acc:0.47333333333333333, test acc:0.364 ===\n",
      "train loss:1.659305211098263\n",
      "train loss:1.7697215745554329\n",
      "train loss:1.6649728753019923\n",
      "=== epoch:186, train acc:0.4766666666666667, test acc:0.363 ===\n",
      "train loss:1.615370857369267\n",
      "train loss:1.6861814105979978\n",
      "train loss:1.7018535084999553\n",
      "=== epoch:187, train acc:0.4766666666666667, test acc:0.3637 ===\n",
      "train loss:1.8080938566761768\n",
      "train loss:1.646084108259179\n",
      "train loss:1.7318477471644464\n",
      "=== epoch:188, train acc:0.49333333333333335, test acc:0.3709 ===\n",
      "train loss:1.6936561287826049\n",
      "train loss:1.6756186427680957\n",
      "train loss:1.7194228801568452\n",
      "=== epoch:189, train acc:0.5, test acc:0.373 ===\n",
      "train loss:1.7215122683949318\n",
      "train loss:1.5431772672640054\n",
      "train loss:1.6164552954546598\n",
      "=== epoch:190, train acc:0.4866666666666667, test acc:0.3714 ===\n",
      "train loss:1.7008323365778273\n",
      "train loss:1.6168732218758015\n",
      "train loss:1.7008945711099894\n",
      "=== epoch:191, train acc:0.48, test acc:0.3684 ===\n",
      "train loss:1.6044766669048989\n",
      "train loss:1.7503124405830854\n",
      "train loss:1.700780594469969\n",
      "=== epoch:192, train acc:0.48333333333333334, test acc:0.3705 ===\n",
      "train loss:1.7537217317326195\n",
      "train loss:1.7209441530010527\n",
      "train loss:1.756496058567388\n",
      "=== epoch:193, train acc:0.49333333333333335, test acc:0.3764 ===\n",
      "train loss:1.6886601618837713\n",
      "train loss:1.688021769100073\n",
      "train loss:1.553382254899003\n",
      "=== epoch:194, train acc:0.49333333333333335, test acc:0.3762 ===\n",
      "train loss:1.6795977964168585\n",
      "train loss:1.6390482952012217\n",
      "train loss:1.6621970035818743\n",
      "=== epoch:195, train acc:0.5, test acc:0.3815 ===\n",
      "train loss:1.7126642220623807\n",
      "train loss:1.6685945093722665\n",
      "train loss:1.6939857548708293\n",
      "=== epoch:196, train acc:0.5066666666666667, test acc:0.3895 ===\n",
      "train loss:1.6528676108725728\n",
      "train loss:1.6523754568359492\n",
      "train loss:1.4710298172425498\n",
      "=== epoch:197, train acc:0.5066666666666667, test acc:0.3894 ===\n",
      "train loss:1.6884644294134878\n",
      "train loss:1.619433068672362\n",
      "train loss:1.5857548128462937\n",
      "=== epoch:198, train acc:0.5166666666666667, test acc:0.3929 ===\n",
      "train loss:1.6919704608145687\n",
      "train loss:1.558338925487325\n",
      "train loss:1.7595417466296148\n",
      "=== epoch:199, train acc:0.52, test acc:0.3966 ===\n",
      "train loss:1.506191276124178\n",
      "train loss:1.6140272375202047\n",
      "train loss:1.6482019722272048\n",
      "=== epoch:200, train acc:0.5266666666666666, test acc:0.3997 ===\n",
      "train loss:1.4662108379694396\n",
      "train loss:1.6148656318140586\n",
      "train loss:1.6417698891579209\n",
      "=== epoch:201, train acc:0.53, test acc:0.4024 ===\n",
      "train loss:1.635532857249027\n",
      "train loss:1.7042165089651748\n",
      "train loss:1.611786733893429\n",
      "=== epoch:202, train acc:0.53, test acc:0.4031 ===\n",
      "train loss:1.5894232487672182\n",
      "train loss:1.5798106262469214\n",
      "train loss:1.7021534358846764\n",
      "=== epoch:203, train acc:0.54, test acc:0.4073 ===\n",
      "train loss:1.5324173196224304\n",
      "train loss:1.5908430383535264\n",
      "train loss:1.6095405021729976\n",
      "=== epoch:204, train acc:0.54, test acc:0.4075 ===\n",
      "train loss:1.5163837314559077\n",
      "train loss:1.6711551221115502\n",
      "train loss:1.5964854739696395\n",
      "=== epoch:205, train acc:0.5533333333333333, test acc:0.4096 ===\n",
      "train loss:1.4296654890088143\n",
      "train loss:1.7073738219347683\n",
      "train loss:1.6405124706681289\n",
      "=== epoch:206, train acc:0.5433333333333333, test acc:0.4111 ===\n",
      "train loss:1.6308591838273399\n",
      "train loss:1.717769959697082\n",
      "train loss:1.452151726254034\n",
      "=== epoch:207, train acc:0.56, test acc:0.4193 ===\n",
      "train loss:1.63215841712827\n",
      "train loss:1.5616145937254513\n",
      "train loss:1.6329638754001843\n",
      "=== epoch:208, train acc:0.55, test acc:0.4145 ===\n",
      "train loss:1.772273178037485\n",
      "train loss:1.595575732472166\n",
      "train loss:1.727390314463782\n",
      "=== epoch:209, train acc:0.5433333333333333, test acc:0.415 ===\n",
      "train loss:1.5872631288151808\n",
      "train loss:1.5579940393869276\n",
      "train loss:1.4961499998447163\n",
      "=== epoch:210, train acc:0.5566666666666666, test acc:0.4185 ===\n",
      "train loss:1.6227311474418549\n",
      "train loss:1.5318519178656211\n",
      "train loss:1.5664881626977034\n",
      "=== epoch:211, train acc:0.57, test acc:0.4287 ===\n",
      "train loss:1.6608177721220883\n",
      "train loss:1.5660550092550238\n",
      "train loss:1.5766261908147896\n",
      "=== epoch:212, train acc:0.57, test acc:0.4303 ===\n",
      "train loss:1.5407633774442249\n",
      "train loss:1.4609053355782207\n",
      "train loss:1.6470216466151841\n",
      "=== epoch:213, train acc:0.5533333333333333, test acc:0.422 ===\n",
      "train loss:1.5980179817809346\n",
      "train loss:1.6186774155063421\n",
      "train loss:1.5950469717111826\n",
      "=== epoch:214, train acc:0.5533333333333333, test acc:0.4255 ===\n",
      "train loss:1.4807553919599061\n",
      "train loss:1.445801587406782\n",
      "train loss:1.5153507158565236\n",
      "=== epoch:215, train acc:0.55, test acc:0.4238 ===\n",
      "train loss:1.6257108932671118\n",
      "train loss:1.5897456307382802\n",
      "train loss:1.6021535387409933\n",
      "=== epoch:216, train acc:0.5733333333333334, test acc:0.4337 ===\n",
      "train loss:1.4670387265648352\n",
      "train loss:1.6530584627950873\n",
      "train loss:1.5783898984731572\n",
      "=== epoch:217, train acc:0.5766666666666667, test acc:0.4358 ===\n",
      "train loss:1.5820402162986433\n",
      "train loss:1.5832583578674713\n",
      "train loss:1.5404003904284642\n",
      "=== epoch:218, train acc:0.5733333333333334, test acc:0.4391 ===\n",
      "train loss:1.5690590550227808\n",
      "train loss:1.320103879705965\n",
      "train loss:1.5012315118521726\n",
      "=== epoch:219, train acc:0.5766666666666667, test acc:0.4395 ===\n",
      "train loss:1.4917022347402626\n",
      "train loss:1.5423720898738051\n",
      "train loss:1.4577729963209853\n",
      "=== epoch:220, train acc:0.5833333333333334, test acc:0.4449 ===\n",
      "train loss:1.4788822389722598\n",
      "train loss:1.5222994602314157\n",
      "train loss:1.4547740974440837\n",
      "=== epoch:221, train acc:0.5833333333333334, test acc:0.4404 ===\n",
      "train loss:1.586068193938451\n",
      "train loss:1.3305713905541032\n",
      "train loss:1.5776328068671128\n",
      "=== epoch:222, train acc:0.5833333333333334, test acc:0.4382 ===\n",
      "train loss:1.4601533713234138\n",
      "train loss:1.4251582713311408\n",
      "train loss:1.66706967202953\n",
      "=== epoch:223, train acc:0.5833333333333334, test acc:0.4402 ===\n",
      "train loss:1.608227804794941\n",
      "train loss:1.4930171168597024\n",
      "train loss:1.53458915644974\n",
      "=== epoch:224, train acc:0.5966666666666667, test acc:0.4455 ===\n",
      "train loss:1.5918645946429484\n",
      "train loss:1.4727099491679791\n",
      "train loss:1.5163114257311472\n",
      "=== epoch:225, train acc:0.58, test acc:0.4378 ===\n",
      "train loss:1.5497995457285239\n",
      "train loss:1.5094755999803073\n",
      "train loss:1.6187441230440995\n",
      "=== epoch:226, train acc:0.59, test acc:0.4444 ===\n",
      "train loss:1.5305859363632361\n",
      "train loss:1.416870451815626\n",
      "train loss:1.474871010202709\n",
      "=== epoch:227, train acc:0.5933333333333334, test acc:0.446 ===\n",
      "train loss:1.5950431727126204\n",
      "train loss:1.2974195922189184\n",
      "train loss:1.4837130010271702\n",
      "=== epoch:228, train acc:0.59, test acc:0.446 ===\n",
      "train loss:1.395631667074617\n",
      "train loss:1.4753839194985352\n",
      "train loss:1.3851677904635258\n",
      "=== epoch:229, train acc:0.59, test acc:0.445 ===\n",
      "train loss:1.5192555954798572\n",
      "train loss:1.5790892934704355\n",
      "train loss:1.5465649092211746\n",
      "=== epoch:230, train acc:0.5866666666666667, test acc:0.446 ===\n",
      "train loss:1.5172139253865362\n",
      "train loss:1.4677975084839596\n",
      "train loss:1.4206227455840825\n",
      "=== epoch:231, train acc:0.58, test acc:0.4457 ===\n",
      "train loss:1.3405546615021553\n",
      "train loss:1.6805028960360997\n",
      "train loss:1.444617224981086\n",
      "=== epoch:232, train acc:0.5766666666666667, test acc:0.4511 ===\n",
      "train loss:1.4125718995148828\n",
      "train loss:1.4930424958034876\n",
      "train loss:1.3987690514300561\n",
      "=== epoch:233, train acc:0.5766666666666667, test acc:0.4475 ===\n",
      "train loss:1.4186843811055792\n",
      "train loss:1.5417161922788918\n",
      "train loss:1.5053176892273104\n",
      "=== epoch:234, train acc:0.58, test acc:0.4535 ===\n",
      "train loss:1.4374137874103516\n",
      "train loss:1.4303770960677518\n",
      "train loss:1.5371448862331394\n",
      "=== epoch:235, train acc:0.5666666666666667, test acc:0.4512 ===\n",
      "train loss:1.4769743210804278\n",
      "train loss:1.4144373223184288\n",
      "train loss:1.3530092277428716\n",
      "=== epoch:236, train acc:0.5866666666666667, test acc:0.4534 ===\n",
      "train loss:1.3599772353334396\n",
      "train loss:1.4829261286519815\n",
      "train loss:1.37221244938039\n",
      "=== epoch:237, train acc:0.5933333333333334, test acc:0.457 ===\n",
      "train loss:1.549922828702374\n",
      "train loss:1.2798210012086084\n",
      "train loss:1.4991161050184354\n",
      "=== epoch:238, train acc:0.6, test acc:0.4571 ===\n",
      "train loss:1.414361486806051\n",
      "train loss:1.4717343248442885\n",
      "train loss:1.4169156069026454\n",
      "=== epoch:239, train acc:0.59, test acc:0.4558 ===\n",
      "train loss:1.3859750575291159\n",
      "train loss:1.54304084116663\n",
      "train loss:1.4611144737424255\n",
      "=== epoch:240, train acc:0.6, test acc:0.4624 ===\n",
      "train loss:1.4287120858578621\n",
      "train loss:1.4933366480683177\n",
      "train loss:1.415258329270643\n",
      "=== epoch:241, train acc:0.5933333333333334, test acc:0.4589 ===\n",
      "train loss:1.5057825673206822\n",
      "train loss:1.3749089421814833\n",
      "train loss:1.4862468375733715\n",
      "=== epoch:242, train acc:0.61, test acc:0.4722 ===\n",
      "train loss:1.459505042174323\n",
      "train loss:1.4649257873470412\n",
      "train loss:1.5298551675471137\n",
      "=== epoch:243, train acc:0.62, test acc:0.4752 ===\n",
      "train loss:1.5202121905552792\n",
      "train loss:1.5532749173005778\n",
      "train loss:1.4304546850454378\n",
      "=== epoch:244, train acc:0.6133333333333333, test acc:0.4763 ===\n",
      "train loss:1.3090068107213562\n",
      "train loss:1.3544599837370785\n",
      "train loss:1.3907529447295732\n",
      "=== epoch:245, train acc:0.62, test acc:0.4786 ===\n",
      "train loss:1.4750974264452292\n",
      "train loss:1.5035801884692261\n",
      "train loss:1.4327788302777384\n",
      "=== epoch:246, train acc:0.62, test acc:0.4829 ===\n",
      "train loss:1.4463901004781237\n",
      "train loss:1.4257336682082227\n",
      "train loss:1.441323505291894\n",
      "=== epoch:247, train acc:0.6266666666666667, test acc:0.4882 ===\n",
      "train loss:1.335370491546947\n",
      "train loss:1.6213463140033284\n",
      "train loss:1.4667104362136354\n",
      "=== epoch:248, train acc:0.6266666666666667, test acc:0.4895 ===\n",
      "train loss:1.35963633062317\n",
      "train loss:1.3971789271882176\n",
      "train loss:1.2632985903403728\n",
      "=== epoch:249, train acc:0.6433333333333333, test acc:0.4906 ===\n",
      "train loss:1.326761977721299\n",
      "train loss:1.271357367783233\n",
      "train loss:1.3813957343822445\n",
      "=== epoch:250, train acc:0.6233333333333333, test acc:0.4852 ===\n",
      "train loss:1.3957738832439506\n",
      "train loss:1.5002566388382852\n",
      "train loss:1.4495974120154012\n",
      "=== epoch:251, train acc:0.64, test acc:0.495 ===\n",
      "train loss:1.279529798257018\n",
      "train loss:1.3040699746893538\n",
      "train loss:1.47120159323006\n",
      "=== epoch:252, train acc:0.63, test acc:0.4906 ===\n",
      "train loss:1.3275052470635254\n",
      "train loss:1.3628725969778\n",
      "train loss:1.4475079931697785\n",
      "=== epoch:253, train acc:0.6233333333333333, test acc:0.4872 ===\n",
      "train loss:1.3779982387112093\n",
      "train loss:1.2100576071528437\n",
      "train loss:1.3206728544714548\n",
      "=== epoch:254, train acc:0.6133333333333333, test acc:0.4863 ===\n",
      "train loss:1.3571533063091172\n",
      "train loss:1.4346374020965078\n",
      "train loss:1.441847997590232\n",
      "=== epoch:255, train acc:0.6166666666666667, test acc:0.4895 ===\n",
      "train loss:1.4070936855102483\n",
      "train loss:1.3366293712941202\n",
      "train loss:1.3596994447111328\n",
      "=== epoch:256, train acc:0.6233333333333333, test acc:0.4932 ===\n",
      "train loss:1.4189150619959463\n",
      "train loss:1.464817857274352\n",
      "train loss:1.4104484747225863\n",
      "=== epoch:257, train acc:0.6233333333333333, test acc:0.502 ===\n",
      "train loss:1.3406944190383312\n",
      "train loss:1.4790761045670748\n",
      "train loss:1.2660705574206033\n",
      "=== epoch:258, train acc:0.62, test acc:0.496 ===\n",
      "train loss:1.5009232074348569\n",
      "train loss:1.3610840642775448\n",
      "train loss:1.3713451213209504\n",
      "=== epoch:259, train acc:0.6266666666666667, test acc:0.4967 ===\n",
      "train loss:1.3654224989449109\n",
      "train loss:1.4067609428407517\n",
      "train loss:1.2419230200039366\n",
      "=== epoch:260, train acc:0.6333333333333333, test acc:0.5028 ===\n",
      "train loss:1.3889526886979593\n",
      "train loss:1.4217393531939309\n",
      "train loss:1.1572142939287584\n",
      "=== epoch:261, train acc:0.6366666666666667, test acc:0.505 ===\n",
      "train loss:1.2352328869596327\n",
      "train loss:1.3417758307432117\n",
      "train loss:1.3153076682661604\n",
      "=== epoch:262, train acc:0.63, test acc:0.5004 ===\n",
      "train loss:1.2247949724038136\n",
      "train loss:1.3180963441264257\n",
      "train loss:1.4303582705838969\n",
      "=== epoch:263, train acc:0.64, test acc:0.5029 ===\n",
      "train loss:1.287761849507173\n",
      "train loss:1.4236886117185505\n",
      "train loss:1.4343007517720525\n",
      "=== epoch:264, train acc:0.6333333333333333, test acc:0.511 ===\n",
      "train loss:1.3524335753391272\n",
      "train loss:1.2515559666673182\n",
      "train loss:1.283226951744062\n",
      "=== epoch:265, train acc:0.6333333333333333, test acc:0.5113 ===\n",
      "train loss:1.2586926146536193\n",
      "train loss:1.3073331987200438\n",
      "train loss:1.3428410584969712\n",
      "=== epoch:266, train acc:0.6333333333333333, test acc:0.5108 ===\n",
      "train loss:1.1248103286393785\n",
      "train loss:1.2196277489283949\n",
      "train loss:1.3938904280807716\n",
      "=== epoch:267, train acc:0.64, test acc:0.5124 ===\n",
      "train loss:1.347011105583595\n",
      "train loss:1.2552873248216931\n",
      "train loss:1.2635909959779037\n",
      "=== epoch:268, train acc:0.64, test acc:0.516 ===\n",
      "train loss:1.3517242002767487\n",
      "train loss:1.4262724204291464\n",
      "train loss:1.4075671949535198\n",
      "=== epoch:269, train acc:0.6466666666666666, test acc:0.5186 ===\n",
      "train loss:1.318555618162028\n",
      "train loss:1.3205755088635345\n",
      "train loss:1.282171647810525\n",
      "=== epoch:270, train acc:0.6466666666666666, test acc:0.5192 ===\n",
      "train loss:1.2775633467943914\n",
      "train loss:1.2117645321680792\n",
      "train loss:1.3611162863641544\n",
      "=== epoch:271, train acc:0.65, test acc:0.519 ===\n",
      "train loss:1.3398948453013408\n",
      "train loss:1.3210451161362236\n",
      "train loss:1.2289058205170598\n",
      "=== epoch:272, train acc:0.6633333333333333, test acc:0.5211 ===\n",
      "train loss:1.2783079060307498\n",
      "train loss:1.1760546254551651\n",
      "train loss:1.2027924659751137\n",
      "=== epoch:273, train acc:0.6633333333333333, test acc:0.521 ===\n",
      "train loss:1.3885746795111513\n",
      "train loss:1.1866638519526758\n",
      "train loss:1.2727049588475636\n",
      "=== epoch:274, train acc:0.6566666666666666, test acc:0.5232 ===\n",
      "train loss:1.3153338938810912\n",
      "train loss:1.2359217243360894\n",
      "train loss:1.2447091890874453\n",
      "=== epoch:275, train acc:0.6633333333333333, test acc:0.5234 ===\n",
      "train loss:1.1932235979784596\n",
      "train loss:1.2846652308984543\n",
      "train loss:1.2864841818042247\n",
      "=== epoch:276, train acc:0.66, test acc:0.5224 ===\n",
      "train loss:1.3628855492452154\n",
      "train loss:1.1449282872642212\n",
      "train loss:1.242118877211675\n",
      "=== epoch:277, train acc:0.67, test acc:0.5268 ===\n",
      "train loss:1.2648637959072415\n",
      "train loss:1.2943208846052392\n",
      "train loss:1.2251673926492208\n",
      "=== epoch:278, train acc:0.66, test acc:0.525 ===\n",
      "train loss:1.1518622475128957\n",
      "train loss:1.2192265054733569\n",
      "train loss:1.267055238103059\n",
      "=== epoch:279, train acc:0.66, test acc:0.527 ===\n",
      "train loss:1.2683498541639997\n",
      "train loss:1.3011136856794707\n",
      "train loss:1.2949721279698863\n",
      "=== epoch:280, train acc:0.6566666666666666, test acc:0.5257 ===\n",
      "train loss:1.2478377812598918\n",
      "train loss:1.1440888324383993\n",
      "train loss:1.3004255080595855\n",
      "=== epoch:281, train acc:0.6533333333333333, test acc:0.5263 ===\n",
      "train loss:1.1511508146707923\n",
      "train loss:1.209484161408807\n",
      "train loss:1.2880641395879646\n",
      "=== epoch:282, train acc:0.6533333333333333, test acc:0.5283 ===\n",
      "train loss:1.2489340565836573\n",
      "train loss:1.2668024338909272\n",
      "train loss:1.2795739810950635\n",
      "=== epoch:283, train acc:0.6766666666666666, test acc:0.5352 ===\n",
      "train loss:1.062210980260421\n",
      "train loss:1.2089677273670882\n",
      "train loss:1.128554752060457\n",
      "=== epoch:284, train acc:0.6733333333333333, test acc:0.5338 ===\n",
      "train loss:1.1914201882462825\n",
      "train loss:1.210182691705173\n",
      "train loss:1.1624832049800562\n",
      "=== epoch:285, train acc:0.6733333333333333, test acc:0.5353 ===\n",
      "train loss:1.2271097164998448\n",
      "train loss:1.1525691161081242\n",
      "train loss:1.173042983606643\n",
      "=== epoch:286, train acc:0.66, test acc:0.5361 ===\n",
      "train loss:1.1997534052898877\n",
      "train loss:1.3914225316935818\n",
      "train loss:1.1416762186268483\n",
      "=== epoch:287, train acc:0.6633333333333333, test acc:0.5378 ===\n",
      "train loss:1.2113990013956673\n",
      "train loss:1.0984774022955108\n",
      "train loss:1.080147423081387\n",
      "=== epoch:288, train acc:0.6633333333333333, test acc:0.5389 ===\n",
      "train loss:1.2355185165347138\n",
      "train loss:1.1188492632979297\n",
      "train loss:1.1600594454079074\n",
      "=== epoch:289, train acc:0.6666666666666666, test acc:0.5371 ===\n",
      "train loss:1.2529023577759542\n",
      "train loss:1.1808837087316606\n",
      "train loss:1.1985745698271957\n",
      "=== epoch:290, train acc:0.6733333333333333, test acc:0.5385 ===\n",
      "train loss:1.2155753165769292\n",
      "train loss:1.216820650475409\n",
      "train loss:1.1878853976837067\n",
      "=== epoch:291, train acc:0.6666666666666666, test acc:0.5406 ===\n",
      "train loss:1.2384313833455716\n",
      "train loss:1.184210580529254\n",
      "train loss:1.235994474643333\n",
      "=== epoch:292, train acc:0.67, test acc:0.5404 ===\n",
      "train loss:1.2546430676444398\n",
      "train loss:1.1635715440892487\n",
      "train loss:1.1229896697693194\n",
      "=== epoch:293, train acc:0.6833333333333333, test acc:0.5439 ===\n",
      "train loss:1.3124946569664118\n",
      "train loss:1.031981834141299\n",
      "train loss:1.3927072009225137\n",
      "=== epoch:294, train acc:0.6866666666666666, test acc:0.5484 ===\n",
      "train loss:1.1896628737227641\n",
      "train loss:1.0950234135154242\n",
      "train loss:1.1635922373772951\n",
      "=== epoch:295, train acc:0.6833333333333333, test acc:0.5478 ===\n",
      "train loss:1.0639225606892502\n",
      "train loss:1.15023393118014\n",
      "train loss:1.1867254950618626\n",
      "=== epoch:296, train acc:0.6866666666666666, test acc:0.5463 ===\n",
      "train loss:1.2556978526463227\n",
      "train loss:1.197361359877017\n",
      "train loss:1.1257498955435097\n",
      "=== epoch:297, train acc:0.68, test acc:0.5483 ===\n",
      "train loss:1.1674588311760024\n",
      "train loss:1.1910772212346028\n",
      "train loss:1.260334688910512\n",
      "=== epoch:298, train acc:0.69, test acc:0.5508 ===\n",
      "train loss:1.1499083453828554\n",
      "train loss:1.1782409360548314\n",
      "train loss:1.1923117587366086\n",
      "=== epoch:299, train acc:0.6866666666666666, test acc:0.5506 ===\n",
      "train loss:1.126638415784501\n",
      "train loss:1.0552960740378088\n",
      "train loss:1.1484357433526\n",
      "=== epoch:300, train acc:0.6866666666666666, test acc:0.55 ===\n",
      "train loss:1.047985878606213\n",
      "train loss:1.1935706304168896\n",
      "train loss:1.1020270441021263\n",
      "=== epoch:301, train acc:0.68, test acc:0.5493 ===\n",
      "train loss:1.2716715907419398\n",
      "train loss:1.2692056746564753\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5522\n"
     ]
    }
   ],
   "source": [
    "#学習と推論\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# グラフの描画==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "#10刻みにポイント\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='D', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
